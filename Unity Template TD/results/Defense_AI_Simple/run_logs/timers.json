{
    "name": "root",
    "gauges": {
        "DefenseAgent.Policy.Entropy.mean": {
            "value": 2.531342029571533,
            "min": 2.4861390590667725,
            "max": 2.531342029571533,
            "count": 47
        },
        "DefenseAgent.Policy.Entropy.sum": {
            "value": 25328.607421875,
            "min": 24585.93359375,
            "max": 25482.390625,
            "count": 47
        },
        "DefenseAgent.Step.mean": {
            "value": 469958.0,
            "min": 9965.0,
            "max": 469958.0,
            "count": 47
        },
        "DefenseAgent.Step.sum": {
            "value": 469958.0,
            "min": 9965.0,
            "max": 469958.0,
            "count": 47
        },
        "DefenseAgent.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.17956244945526123,
            "min": -0.7849973440170288,
            "max": 0.21617773175239563,
            "count": 47
        },
        "DefenseAgent.Policy.ExtrinsicValueEstimate.sum": {
            "value": 30.166492462158203,
            "min": -129.52456665039062,
            "max": 36.101680755615234,
            "count": 47
        },
        "DefenseAgent.Environment.EpisodeLength.mean": {
            "value": 335.5,
            "min": 313.4193548387097,
            "max": 360.6666666666667,
            "count": 47
        },
        "DefenseAgent.Environment.EpisodeLength.sum": {
            "value": 10736.0,
            "min": 9245.0,
            "max": 10762.0,
            "count": 47
        },
        "DefenseAgent.Environment.CumulativeReward.mean": {
            "value": 0.625,
            "min": 0.5,
            "max": 1.0,
            "count": 47
        },
        "DefenseAgent.Environment.CumulativeReward.sum": {
            "value": 20.0,
            "min": 16.0,
            "max": 28.0,
            "count": 47
        },
        "DefenseAgent.Policy.ExtrinsicReward.mean": {
            "value": 0.625,
            "min": 0.5,
            "max": 1.0,
            "count": 47
        },
        "DefenseAgent.Policy.ExtrinsicReward.sum": {
            "value": 20.0,
            "min": 16.0,
            "max": 28.0,
            "count": 47
        },
        "DefenseAgent.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 47
        },
        "DefenseAgent.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 47
        },
        "DefenseAgent.Losses.PolicyLoss.mean": {
            "value": 0.022978703874832716,
            "min": 0.01882891289684873,
            "max": 0.03281670792105918,
            "count": 45
        },
        "DefenseAgent.Losses.PolicyLoss.sum": {
            "value": 0.022978703874832716,
            "min": 0.01882891289684873,
            "max": 0.03281670792105918,
            "count": 45
        },
        "DefenseAgent.Losses.ValueLoss.mean": {
            "value": 0.01955883012463649,
            "min": 0.015513635923465092,
            "max": 0.06139212461809317,
            "count": 45
        },
        "DefenseAgent.Losses.ValueLoss.sum": {
            "value": 0.01955883012463649,
            "min": 0.015513635923465092,
            "max": 0.06139212461809317,
            "count": 45
        },
        "DefenseAgent.Policy.LearningRate.mean": {
            "value": 3.84399231202e-05,
            "min": 3.84399231202e-05,
            "max": 4.974287551425001e-05,
            "count": 45
        },
        "DefenseAgent.Policy.LearningRate.sum": {
            "value": 3.84399231202e-05,
            "min": 3.84399231202e-05,
            "max": 4.974287551425001e-05,
            "count": 45
        },
        "DefenseAgent.Policy.Epsilon.mean": {
            "value": 0.1768798,
            "min": 0.1768798,
            "max": 0.19948575000000002,
            "count": 45
        },
        "DefenseAgent.Policy.Epsilon.sum": {
            "value": 0.1768798,
            "min": 0.1768798,
            "max": 0.19948575000000002,
            "count": 45
        },
        "DefenseAgent.Policy.Beta.mean": {
            "value": 0.007690292019999998,
            "min": 0.007690292019999998,
            "max": 0.009948626424999999,
            "count": 45
        },
        "DefenseAgent.Policy.Beta.sum": {
            "value": 0.007690292019999998,
            "min": 0.007690292019999998,
            "max": 0.009948626424999999,
            "count": 45
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1689940455",
        "python_version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "F:\\MLAgents_Unity\\venv\\Scripts\\mlagents-learn config\\DefenseAI.yaml --env=TrainingsEnvs/UnityTemplateTD --num-envs=5 --run-id=Defense_AI_Simple --force",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cu110",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1689943551"
    },
    "total": 3096.1366698,
    "count": 1,
    "self": 0.503964200000155,
    "children": {
        "run_training.setup": {
            "total": 0.3845071,
            "count": 1,
            "self": 0.3845071
        },
        "TrainerController.start_learning": {
            "total": 3095.2481985,
            "count": 1,
            "self": 3.659777500035034,
            "children": {
                "TrainerController._reset_env": {
                    "total": 13.638557299999999,
                    "count": 1,
                    "self": 13.638557299999999
                },
                "TrainerController.advance": {
                    "total": 3077.7048219999656,
                    "count": 121050,
                    "self": 2.4950322999789023,
                    "children": {
                        "env_step": {
                            "total": 2865.5618592000324,
                            "count": 121050,
                            "self": 163.61032220011657,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 2699.137916099952,
                                    "count": 478621,
                                    "self": 32.70303129987087,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 2666.434884800081,
                                            "count": 477482,
                                            "self": 2666.434884800081
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 2.813620899964011,
                                    "count": 121049,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 15413.107644899841,
                                            "count": 478619,
                                            "is_parallel": true,
                                            "self": 13768.129619999689,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.022307800000001876,
                                                    "count": 5,
                                                    "is_parallel": true,
                                                    "self": 0.010878000000005272,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.011429799999996604,
                                                            "count": 20,
                                                            "is_parallel": true,
                                                            "self": 0.011429799999996604
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 1644.9557171001522,
                                                    "count": 478619,
                                                    "is_parallel": true,
                                                    "self": 41.42932180018056,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 38.245896800058304,
                                                            "count": 478619,
                                                            "is_parallel": true,
                                                            "self": 38.245896800058304
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 1420.5504218999527,
                                                            "count": 478619,
                                                            "is_parallel": true,
                                                            "self": 1420.5504218999527
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 144.73007659996085,
                                                            "count": 478619,
                                                            "is_parallel": true,
                                                            "self": 65.86098070014035,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 78.86909589982051,
                                                                    "count": 1914476,
                                                                    "is_parallel": true,
                                                                    "self": 78.86909589982051
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 209.64793049995413,
                            "count": 121049,
                            "self": 3.9025327999081583,
                            "children": {
                                "process_trajectory": {
                                    "total": 76.56300750004542,
                                    "count": 121049,
                                    "self": 74.17951980004526,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 2.3834877000001597,
                                            "count": 9,
                                            "self": 2.3834877000001597
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 129.18239020000055,
                                    "count": 46,
                                    "self": 69.49251369999857,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 59.689876500001986,
                                            "count": 1380,
                                            "self": 59.689876500001986
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 7.999997251317836e-07,
                    "count": 1,
                    "self": 7.999997251317836e-07
                },
                "TrainerController._save_models": {
                    "total": 0.2450408999998217,
                    "count": 1,
                    "self": 0.008146399999986897,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.2368944999998348,
                            "count": 1,
                            "self": 0.2368944999998348
                        }
                    }
                }
            }
        }
    }
}