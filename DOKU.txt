Doku: Anfangsziel war rudimentäres Spiel zu bauen um Aspekte zu testen und zu lernen. Das führte zu mehreren Iterationen besonders an der SteuerungBeim Auseinandersetzen mit MLAgents ist mir aufgefallen, dass die Art auf die Rewards in Reinforced Learning gegeben werden eine hohe Chance hat nicht kompatibel mit der Genre des Spiels zu sein, da
      die Rewards durch seperate Handlungen von Einheiten gegeben werden soll, zudem das Agenten Skript nicht natürlichweise direkten Zugriff hat. Sofern ist der Zyklus des Reinforced learning hierdurch bei dem "Reward" Schritt verzögert, falls Rewards außerhalb dieses Skripts gegeben werden sollen. Deshalb lag für mich hierauf der Fokus während der Einarbeitung und hierfür wurden auch die meisten Iterationen gemacht, um das auf irgendeine weise zu ermöglichen.
      Wichtig war außerdem die Benutzung und Einstellung der Konfigurationsdatei des Netzwerks. Das Training kann um einige größen effizienter sein, wenn man es richtig an seine Situation anpasst. Nicht zu vergessen Curriculum Training existiert.
      Steuerung ist sehr wichtig. Programmatisch ist die Steuerung für die AI nichts speziell anspruchsvolles. Für das Selbstspielen durch die Implementierung der Heuristic Funktion (welche blablabla...) merkt man aber direkt, dass mehrere bestimmte Befehle nicht direkt gegeben werden können. Man kann also im normalfall nicht direkt diagonal gehen, wenn man eine Steuerung implementiert hat
      welche die normale WASD Steuerung abbilden soll. Generell war ein wichtiger Aspekt, welcher öfter geändert wurde geprägt durch die Frage "Wie rudimentär kann oder muss ich dieses Feature machen, um das Verhalten durch den Agenten und seine Umgebung zu bekommen, die ich will".

22.06.2023 Die Wahl viel auf ein sehr bekanntes Spiel Konzept für das Thema, eine Tower Defense. Nicht ganz die allseits bekannte Art, sondern wie in Wintermaul Wars in WC III. Die Idee war zu Anfangs zwei Spieler zu haben, welche jeweils eine limitierte Fläche zum bauen haben und diese benutzen um Türme zu bauen, aber gleichzeitig auch Ressourcen verbrauchen um Einheiten gegen den Gegner los zuschicken. Das Ziel war die Einheiten bis in die gegnerische Basis zu senden, wo sie Lebenspunkte abziehen sollen, bis dieser 0 Lebenspunkte hat. Das Layout und der Mix aus verschiedenen Turm Typen ist wichtig für die Defensive. Sowohl auch eine Balance zwischen senden versch. Einheiten
und bauen der Türme. Aber zwei KI zu haben welche auf "verschiedenene" Konzepte (Angriff und Defensive) gleichzeitig trainiert werden, hat sich auf weiteren Blick als zu komplex für diese Arbeit herausgestellt. Die Wahl viel auf ein Asymmetry, bei der ein Spieler die Defensive hat und der andere die Offensive (Monster schicken). So ist hier noch ausreichend Komplexität zu finden um die KI zu trainieren gegeneinander zu spielen und sich zu verbessern. Die Höhe der Komplexität die man hier erreichen kann ist beliebig und wird je nach Eigenresultat angepasst.    
Wichtig gegen Anfang war das richtige Layout des Tower Defense spiels zu finden -> hier anlehnung and Wintermaul Wars und ähnliche "Fun Games" im Spiel Warcraft III. Ziel war es Ein  anfangs simples Spielfeld zu haben, das nach Bedarf erweitert werden kann, so muss also der Code gut und schnell anpassbar sein. Hier war ein sehr gut anpassbares Grid System erforderlich, um eine eventuell große und Komplexe Anzahl an Informationen zu speichern.
      Dies wird nicht nur bei dem Platzieren der Türme wichtig, sondern auch für das Pathfinding der Monster und weiter in die Zukunft geschaut, für das Logging und visualisieren und Daten.

23.06.2023 mehr Modularität innerhalb der Grid Cells durch einfügen komplexer Objekte als Referenz Punkt für eine Zelle. Entscheidung für Einfaches Targetting, nicht Physiks based bei Projektilen (for now)